<!DOCTYPE html>
































<html
  class="not-ready text-sm lg:text-base"
  style="--bg: #f1efe1"
  lang="en-us"
>
  <head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta
    name="viewport"
    content="width=device-width, initial-scale=1, shrink-to-fit=no"
  />

  
  <title>My First Engagement in Fault Detection with the Help of the Inspection Robot in the Chiller Plant - Carry HE</title>

  
  <meta name="theme-color" />
  
  <meta name="description" content="Background Industrial Fault Detection and Diagnosis (I-FDD) are in the process of deployment in practice, which is inspiring and exciting. For example, the latest inspection robots showed up at the 4th BAIDU OpenI/O QIZHI Developers Conference, which has come to end. The robot is typically designed for the transformer substations, which take into account the complex layout (steps, slope, etc.). It occurs to me that my previous experience, in which I was involved in developing and testing the algorithms for FDD based on the inspection robot in the chiller plant." />
  <meta
    name="author"
    content="Carry HE"
  />
  

  
  
  
  
  
  
  <link rel="preload stylesheet" as="style" href="https://carrybio.netlify.app/main.min.css" />

  
  <script
    defer
    src="https://carrybio.netlify.app/highlight.min.js"
    onload="hljs.initHighlightingOnLoad();"
  ></script>
  

  
   
  <link rel="preload" as="image" href="https://carrybio.netlify.app/theme.png" />

  
  
  
  <link rel="preload" as="image" href="https://avatars.githubusercontent.com/u/56281608?v=4" />
  
  

  
  <link rel="preload" as="image" href="https://carrybio.netlify.app/github.svg" />
  

  
  <link rel="icon" href="https://carrybio.netlify.app/favicon.ico" />
  <link rel="apple-touch-icon" href="https://carrybio.netlify.app/apple-touch-icon.png" />

  
  <meta name="generator" content="Hugo 0.110.0">

  
  

  
  
  
  
  
  
  
  
  
  <meta property="og:title" content="My First Engagement in Fault Detection with the Help of the Inspection Robot in the Chiller Plant" />
<meta property="og:description" content="Background Industrial Fault Detection and Diagnosis (I-FDD) are in the process of deployment in practice, which is inspiring and exciting. For example, the latest inspection robots showed up at the 4th BAIDU OpenI/O QIZHI Developers Conference, which has come to end. The robot is typically designed for the transformer substations, which take into account the complex layout (steps, slope, etc.). It occurs to me that my previous experience, in which I was involved in developing and testing the algorithms for FDD based on the inspection robot in the chiller plant." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://carrybio.netlify.app/posts/blog14/" /><meta property="og:image" content="https://carrybio.netlify.app/posts/blog14/blog14-cover.jpg"/><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-04-08T14:45:46+08:00" />
<meta property="article:modified_time" content="2023-04-08T14:45:46+08:00" />

  
  <meta itemprop="name" content="My First Engagement in Fault Detection with the Help of the Inspection Robot in the Chiller Plant">
<meta itemprop="description" content="Background Industrial Fault Detection and Diagnosis (I-FDD) are in the process of deployment in practice, which is inspiring and exciting. For example, the latest inspection robots showed up at the 4th BAIDU OpenI/O QIZHI Developers Conference, which has come to end. The robot is typically designed for the transformer substations, which take into account the complex layout (steps, slope, etc.). It occurs to me that my previous experience, in which I was involved in developing and testing the algorithms for FDD based on the inspection robot in the chiller plant."><meta itemprop="datePublished" content="2023-04-08T14:45:46+08:00" />
<meta itemprop="dateModified" content="2023-04-08T14:45:46+08:00" />
<meta itemprop="wordCount" content="1323"><meta itemprop="image" content="https://carrybio.netlify.app/posts/blog14/blog14-cover.jpg">
<meta itemprop="keywords" content="" />
  
  <meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://carrybio.netlify.app/posts/blog14/blog14-cover.jpg"/>
<meta name="twitter:title" content="My First Engagement in Fault Detection with the Help of the Inspection Robot in the Chiller Plant"/>
<meta name="twitter:description" content="Background Industrial Fault Detection and Diagnosis (I-FDD) are in the process of deployment in practice, which is inspiring and exciting. For example, the latest inspection robots showed up at the 4th BAIDU OpenI/O QIZHI Developers Conference, which has come to end. The robot is typically designed for the transformer substations, which take into account the complex layout (steps, slope, etc.). It occurs to me that my previous experience, in which I was involved in developing and testing the algorithms for FDD based on the inspection robot in the chiller plant."/>

  
  

  

  
  
  <script async src="https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js"></script>
  
</head>

  <body class="text-black duration-200 ease-out dark:text-white">
    <header class="mx-auto flex h-[5rem] max-w-3xl px-8 lg:justify-center">
  <div class="relative z-50 mr-auto flex items-center">
    <a
      class="-translate-x-[1px] -translate-y-0.5 text-3xl font-bold"
      href="https://carrybio.netlify.app/"
      >Carry HE</a
    >
    <a
      class="btn-dark ml-6 h-6 w-6 shrink-0 cursor-pointer [background:url(./theme.png)_left_center/_auto_theme('spacing.6')_no-repeat] [transition:_background-position_0.4s_steps(5)] dark:[background-position:right]"
    ></a>
  </div>

  <a
    class="btn-menu relative z-50 -mr-8 flex h-[5rem] w-[5rem] shrink-0 cursor-pointer flex-col items-center justify-center gap-2.5 lg:hidden"
  ></a>

  
  <script>
    
    const htmlClass = document.documentElement.classList;
    setTimeout(() => {
      htmlClass.remove('not-ready');
    }, 10);

    
    const btnMenu = document.querySelector('.btn-menu');
    btnMenu.addEventListener('click', () => {
      htmlClass.toggle('open');
    });

    
    const metaTheme = document.querySelector('meta[name="theme-color"]');
    const lightBg = `"#f1efe1"`.replace(/"/g, '');
    const setDark = (isDark) => {
      metaTheme.setAttribute('content', isDark ? '#000' : lightBg);
      htmlClass[isDark ? 'add' : 'remove']('dark');
      localStorage.setItem('dark', isDark);
    };

    
    const darkScheme = window.matchMedia('(prefers-color-scheme: dark)');
    if (htmlClass.contains('dark')) {
      setDark(true);
    } else {
      const darkVal = localStorage.getItem('dark');
      setDark(darkVal ? darkVal === 'true' : darkScheme.matches);
    }

    
    darkScheme.addEventListener('change', (event) => {
      setDark(event.matches);
    });

    
    const btnDark = document.querySelector('.btn-dark');
    btnDark.addEventListener('click', () => {
      setDark(localStorage.getItem('dark') !== 'true');
    });
  </script>

  <div
    class="nav-wrapper fixed inset-x-0 top-full z-40 flex h-full select-none flex-col justify-center pb-16 duration-200 dark:bg-black lg:static lg:h-auto lg:flex-row lg:!bg-transparent lg:pb-0 lg:transition-none"
  >
    
    
    <nav class="lg:ml-12 lg:flex lg:flex-row lg:items-center lg:space-x-6">
      
      <a
        class="block text-center text-2xl leading-[5rem] lg:text-base lg:font-normal"
        href="/about/"
        >About</a
      >
      
      <a
        class="block text-center text-2xl leading-[5rem] lg:text-base lg:font-normal"
        href="/posts/"
        >Posts</a
      >
      
      <a
        class="block text-center text-2xl leading-[5rem] lg:text-base lg:font-normal"
        href="/publications/"
        >Publications</a
      >
      
    </nav>
    

    
    <nav
      class="mt-12 flex justify-center space-x-10 dark:invert lg:mt-0 lg:ml-12 lg:items-center lg:space-x-6"
    >
      
      <a
        class="h-8 w-8 [background:var(--url)_center_center/cover_no-repeat] lg:h-6 lg:w-6"
        style="--url: url(./github.svg)"
        href=" https://github.com/Hurricane-k "
        target="_blank"
      ></a>
      
    </nav>
    
  </div>
</header>


    <main
      class="prose prose-neutral relative mx-auto min-h-[calc(100%-10rem)] max-w-3xl px-8 pt-20 pb-32 dark:prose-invert"
    >
      

<article>
  <header class="mb-20">
    <h1 class="!my-0 pb-2.5">My First Engagement in Fault Detection with the Help of the Inspection Robot in the Chiller Plant</h1>

    
    <div class="text-sm opacity-60">
      
      <time>Apr 8, 2023</time>
      
      
      <span class="mx-1">&middot;</span>
      <span>Carry HE</span>
      
    </div>
    
  </header>

  <section><div align=center><img src="blog14-cover.jpg"></div>
<h1 id="background">Background</h1>
<p>Industrial Fault Detection and Diagnosis (I-FDD) are in the process of deployment in practice, which is inspiring and exciting. For example, the latest inspection robots showed up at the 4th BAIDU OpenI/O QIZHI Developers Conference, which has come to end. The robot is typically designed for the transformer substations, which take into account the complex layout (steps, slope, etc.). It occurs to me that my previous experience, in which I was involved in developing and testing the algorithms for FDD based on the inspection robot in the chiller plant. The recent events indicate the inevitable tendency to digitize the job of inspection. After all, the position related to plant inspection work is uncomfortable for people. The inspection robots can reduce the miserable burden for human beings to a certain degree.</p>
<div align=center><img src="blog14-bg1Eng.png"></div>
<div align=center><img src="blog14-bg2Eng.png"></div>
<div align=center><img src="blog14-bg3Eng.png"></div>
<h1 id="goals">Goals</h1>
<p>Our previous work aims at Fault Detection other than Fault Diagnosis. Both concepts are essentially different. Fault Detection is the foundation of Fault Diagnosis. Fault Diagnosis is the further step of Fault Detection. Disclaimer: the following description dedicates that the inspection robot needs to be equipped with more than one camera sensor, more than one microphone (or audio sensor), and more than one infrared sensor.</p>
<div align=center><img src="blog14-GeneralWorkflow.jpg"></div>
<p>Our algorithm consists of a few parts: image recognition by RGB images, fault detection by infrared photos, fault detection by RGB images, and fault detection by audio. The inspection objects include the critical components in chiller plants: pipes, chillers, and water pumps.</p>
<p><div class="mermaid">
  
flowchart LR
    A[Our Solution\n for Fault Detection] --> B[Data]
    B --> B1[RGB images]
    B --> B2[infrared photos]
    B --> B3[audio]
    B1 --> B11[equipment photos]
    B1 --> B12[dial photos]
    B11 --> C1[equipment\n classification]
    B12 --> C2[inspect the\n temperature\n or pressure\n of pipes]
    B2 --> C3[inspect the temperature\n of equipment]
    B3 --> C4[detect whether or not\n equipment has problems]

</div>
 </p>
<h1 id="rgb-image-based-equipment-classification">RGB Image-based Equipment Classification</h1>
<p>When the robot patrols the chiller room, it takes many pictures (of <em><strong>chillers</strong></em>, <em><strong>water pumps</strong></em>, <em><strong>temperature dials</strong></em>, and <em><strong>pressure dials</strong></em>) with the help of technology Light Detection and Ranging (LIDAR), which is a method for measuring distances by illuminating the target with laser light and measuring the reflection with a sensor. When the equipment is identified accurately, further diagnosis makes sense. We adopt the modified AlexNet to recognize by the RGB images. The feature extraction remains unchanged, and the part of the classification is rebuilt according to the requirements of the issues to be addressed: to change the output of the fully connected layer to 4 (Number 4 means the things we mentioned before). In model training, only the parameters for the classification are updated. The rotated and mirror are used to enhance the images we have.</p>
<div align=center><img src="blog14-Classification.jpg"></div>
<h1 id="dial-indicator-reading">Dial Indicator Reading</h1>
<p>It is rare to see dials in recently-built plants, but they are common in some old plants, usually telling engineers the pressure and temperature in pipes. This part can digitize the old plants at a low cost: reading dials and identifying the values.</p>
<div class="mermaid">
  
flowchart LR
    A["Inital RGB\n iamge(dial)"] --> B["Scaling/Rotating"]
    B --> B1["R-channel\ngrayscale"]
    B --> B2["G-channel\ngrayscale"]
    B --> B3["B-channel\ngrayscale"]
    B1 & B2 & B3 --> C[AND]
    C --> D[Extract\n Pointer]
    D --> E[Calculate the Angle\n Between Needle Tip\n and the Negative Y-Axis]
    E --> F["Convert Angle\n to Temperature/Pressure"]
    F --> G["Fault\n Detection"]

</div>
<p>Standardized photography should be obtained before reading the dial to make the readings more accurate. As a side note, the dial should be vertical and centered on the photograph. This part of the algorithm can be divided into three parts:</p>
<ol>
<li>identify the position of the pointer.</li>
<li>calculate the angle between the pointer and the negative y-axis, which help us obtain the angle between the pointer and the zero mark.</li>
<li>convert the angle between the pointer and the zero mark to the corresponding pressure or temperature value.</li>
<li>Image scaling/rotating mainly involves adjusting the image&rsquo;s resolution and size without losing the necessary information. When the ratio of height to width of the input image is less than 1, it is designed to rotate 90° counterclockwise.</li>
</ol>
<div align=center><img src="blog14-IllustrativeDialRead.jpg"></div>
<h1 id="recognition-in-infrared-images">Recognition in Infrared Images</h1>
<p>The temperature of a piece of running equipment is also a key indicator of whether or not the condition is good. In every infrared image shot by FLIR infrared cameras, reading the number in the upper right corner helps the staff to know the highest temperature.</p>
<div class="mermaid">
  
flowchart LR
    A[Intial\n Infrared Image] --> B[Image Cropping]
    B --> C[Image\n Grayscale]
    C --> D[Image\n Binarization]
    D --> E[Image\n Enlargement]
    E --> F[Reading\n OCR]
    F --> G[Temperature]

</div>
<p>Using the temperature reading of the infrared pump image as an illustrative example, it is achieved with the help of Python’s <a href="https://github.com/tesseract-ocr/tesseract">pytesseract</a> and <a href="https://github.com/scikit-image/scikit-image">skimage</a>. The proposed algorithm can accurately read the temperature on an infrared image. The identified maximum temperature of the pump can help the purpose of fault diagnosis. By the way, the proposed non-intrusive approach cannot measure the maximum temperature of the internal part of a motor.</p>
<div align=center><img src="blog14-IllustrativeInfraredRead.jpg"></div>
<h1 id="audio-based-fault-detection">Audio-based Fault Detection</h1>
<p>Generally, when a piece of equipment is in good condition, the sound that it generates would smooth. When equipment cannot work well, the sound usually becomes sharp. Our audio-based method utilizes this property. If we can determine the threshold between smooth and sharp sounds, some problems can be detected in time.</p>
<p>The typical signal process inspires this part. Discrete Fourier Transform (DFT) converts audio from the time domain to the frequency domain. Usually, the audio is a mix of the sound from the target and the sound from other equipment. So separating the target&rsquo;s and other equipment&rsquo;s sounds is essential before analyzing the frequency domain. DFT can help us do this. The result of DFT can give us a clear visualization of the frequency domain.</p>
<p>In our audio-based detection, we use the ARIMA model, usually applied in financial analysis, to fit the pump high-, medium-, and low-frequency domain signals. If the audio is non-smooth, the d-order difference operation is first performed to turn it into a smooth time series. For smooth audio, the ARIMA model is used directly. So we can identify smooth and other audio.</p>
<h1 id="acknowledge">Acknowledge</h1>
<ol>
<li><em><strong><font color=blue>Big big thank you to some of my older research group mates. They made the majority of contributions to this work. Without him, this work cannot be here. They are so nice and patient to help me to start other research independently.</font></strong></em> If you are interested in our study, or if it inspires you, don&rsquo;t hesitate to click <a href="https://www.sciencedirect.com/science/article/pii/S0378778821002516">here</a> to learn more details.</li>
<li><strong>Big big thank you to some companies who trust us and sponsor us to start and improve the idea of the inspection robots.</strong></li>
<li>The first picture cited at the beginning is from <a href="https://unsplash.com/">Unsplash.com</a> and Photographer <a href="https://unsplash.com/@spacexuan"><em>Crystal Kwok</em></a>.</li>
</ol>
<h1 id="future-work">Future Work</h1>
<ol>
<li>Regarding our audio-based Fault Detection, sharp sounds cannot represent all problems the engineers would come across. Given the lack of collection of abnormal audio, it is nearly impossible to analyze more sound-related features from equipment that operates in good condition. Deliberately damaging a piece of equipment is unaffordable. If the collection of sounds has more diversity, a more detailed analysis will help to develop a more refined audio-based Fault Detection method.</li>
<li>It is not flexible to read dials in our design because the dial photos are required to be shot against a black background. The colorful background would make our method cannot work well. In the future plan, this part of the method will be improved to face more complicated situations.</li>
<li>The rapid development of large AI models makes AlexNet relatively old-fashion. This part should be improved by following the latest technologies. In addition, the classification needs to be more detailed and encompass more equipment.</li>
</ol>
<h1 id="reference">Reference</h1>
<ol>
<li>
<p>R He, P Xu, Z Chen, W Luo, Z Su, J Mao, A non-intrusive approach for fault detection and diagnosis of water distribution systems based on image sensors, audio sensors and an inspection robot, Energy and Buildings, Volume 243, 2021, 110967, ISSN 0378-7788.</p>
</li>
<li>
<p><a href="https://nanonets.com/blog/ocr-with-tesseract/">Tesseract OCR in Python with Pytesseract andOpenCV</a></p>
</li>
<li>
<p><a href="https://github.com/tesseract-ocr/tesseract">GitHub - tesseract-ocr/tesseract: Tesseract Open Source OCR Engine (main repository)</a></p>
</li>
<li>
<p><a href="https://github.com/scikit-image/scikit-image">GitHub - scikit-image/scikit-image: Image processing in Python</a></p>
</li>
<li>
<p><a href="https://www.investopedia.com/terms/a/autoregressive-integrated-moving-average-arima.asp">Autoregressive Integrated Moving Average (ARIMA) Prediction Model</a></p>
</li>
</ol>
</section>

  
  

  
  
  
  <nav class="mt-24 flex rounded-lg bg-black/[3%] text-lg dark:bg-white/[8%]">
    
    
    <a
      class="ml-auto flex w-1/2 items-center justify-end rounded-r-md p-6 pl-3 no-underline hover:bg-black/[2%]"
      href="https://carrybio.netlify.app/posts/blog13/"
      ><span>Build a Hierarchy Model for Building Energy Saving Facing Engineering Data Differentiation</span><span class="ml-1.5">→</span></a
    >
    
  </nav>
  

  
  

  
  
</article>


    </main>

    <footer
  class="opaco mx-auto flex h-[5rem] max-w-3xl items-center px-8 text-[0.9em] opacity-60"
>
  <div class="mr-auto">
    &copy; 2023
    <a class="link" href="https://carrybio.netlify.app/">Carry HE</a>
  </div>
  <a class="link mx-6" href="https://gohugo.io/" rel="noopener" target="_blank"
    >Powered by Hugo️️</a
  >️

</footer>

  </body>
</html>
